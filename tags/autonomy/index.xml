<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Autonomy on Aiur · Zellux 的博客</title>
    <link>https://blog.yxwang.me/tags/autonomy/</link>
    <description>Recent content in Autonomy on Aiur · Zellux 的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 29 Mar 2019 16:03:45 -0700</lastBuildDate>
    
	<atom:link href="https://blog.yxwang.me/tags/autonomy/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>3D 目标检测之鸟瞰图检测 (Pixor / HDNet)</title>
      <link>https://blog.yxwang.me/2019/03/bev-detection/</link>
      <pubDate>Fri, 29 Mar 2019 16:03:45 -0700</pubDate>
      
      <guid>https://blog.yxwang.me/2019/03/bev-detection/</guid>
      <description>随着无人驾驶的兴起，激光雷达数据的目标检测成为了这几年的研究热点之一。常见的 3D 检测模型可以分成两类，一类是用 3D 小方格代表所有的激光点数据，每个小方格包含了这个方格内的特征，例如 VoxelNet 和 Vote3deep 。另一类则是先把三维信息投射到一个二维平面，通常是鸟瞰图 (BEV, Bird Eye View) 或是正视图 (Range View)，生成二维特征图后再用传统的二维目标模型检测图中的物体，例如 MV3D 和 FaF。
无人驾驶场景中的大多数的目标物体都处在同一地面上，非常适合 BEV。相比正视图，BEV 中的目标在不同位置大小固定，我们可以用已知的常见物体大小优化检测效果。对于 BEV 模型来说，主要的问题在于如何选择最终图像的特征，如何生成的图像中做出精确的检测。此文旨在介绍 BEV 检测相关的模型 Pixor 和 HDNet。
Pixor Pixor 是 Uber ATG 的 Bin Yang 等人在 CVPR 18 上提出的 BEV 检测模型。在特征生成方面，Pixor 把整个点云切成了 L x W x H 个小方格，每个小方格用 0 或 1 表示这个方格内是否有激光点存在，接着沿高度方向把三维特征压缩到一个二维平面，每个压缩后的二维方格就有了 H 个特征表示这个方格上的不同高度是否有点存在。此外 Pixor 还计算了落在每个方格中激光点的平均强度作为额外的特征，最终拿到了一个分辨率为 L x W、包含 H + 1 个特征通道的图像。
 Pixor 结构  检测方面，Pixor 采用了基于 RetinaNet 的 one-stage 的结构，如上图所示（这里用了海报上的截图，和论文中的有一些细小的差别）。网络里面用了 ResNet 和类似 FPN 的结构。FPN 结构输出的特征图经过一个头部网络后，直接生成对每个像素点的分类和 bounding box 的回归结果。</description>
    </item>
    
  </channel>
</rss>