<!DOCTYPE html>
<html lang="zh-CN">

  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="description" content="Multi-Execution: Multicore Caching for Data-Similar Executions
这篇paper针对以multi-execution这种模式运行的程序提出了一种新的cache手段。
所谓multi-execution，指的是同时运行同一个程序的多个进程，而它们的输入数据又互不相同。这种模式在machine-learning领域比较常见，一些相对独立的learner可以以并行的方式被训练，而它们的结果可以通过一种叫做boosting的方式合并起来。给我的感觉似乎有点像mapreduce？
然后呢，作者们发现以这种方式运行的程序进程的数据有很大一部分是相同的，在合并cache数据上可以做一下文章，节省cache的使用。
于是这篇paper提出了一种叫做mergeable cache的架构，用于代替传统的L2 cache，L1 cache还是传统的cache架构。首先假设相同的数据的虚拟地址往往也是相同的（应该去掉了address space randomization的影响），以类似Page Coloring的策略进行物理页的分配，使得不同进程同一虚拟地址所对应的物理页都是相邻的。然后把虚拟地址的头9位作为cache tag，再为每个cache line记录一个bit vector用以表示某个processor的数据是否保存在这条cache line中。于是L2 cache hit当且仅当： 1. 虚拟地址的头9位等于cache line的tag 2. cache line中的bit vector的processor对应的位被置上
另外为了简化cache策略，L1和L2的数据内容是互斥的，或者说一段被cache的数据要么在L1，要么在L2，不可能同时存在于两者中。这样一来L2就只有从L1淘汰出来的数据了，而L2中的数据修改分三步完成： 1. 把数据从L2中标记为不存在（对应processor的bit vector位置0） 2. 数据进入L1 3. 修改数据
这就是这篇paper提出的cache架构的主要内容，后面的evaluation部分做的也很不错。从数据中可以看出合并的cache里面dirty cache占了比较大的比例，从而说明简单的copy-on-write策略的效果不会很好，因为copy-on-write只能合并clean cache。最后平均的speedup提升在2.5x左右，很不错。但是对于数据无关的并行程序运行，会产生一定的overhead，此时可以选择传统的L2 cache机制。">
    <meta name="author" content="zellux">

    <title> ISCA 09 - Multi-Execution &middot; Aiur · Zellux 的博客 </title>

    <script src="/js/jquery-3.2.1.min.js"></script>
    <link rel="stylesheet" href="/css/jquery.fancybox.min.css" />
    <script src="/js/jquery-3.0.47.fancybox.min.js"></script>

    
    
    <link rel="stylesheet" href="https://blog.yxwang.me/css/slim.min.52ea10a8f3a0b8f145adadb8d3761e17a42a7634869f775ef5830ed4de77d3fa.css">
    
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Source+Code+Pro' rel='stylesheet' type='text/css'>
    
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.ico">

    
    <link href="" rel="alternate" type="application/rss+xml" title="Aiur · Zellux 的博客" />
    
<script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://blog.yxwang.me/"
    },
    "articleSection" : "post",
    "name" : "ISCA 09 - Multi-Execution",
    "headline" : "ISCA 09 - Multi-Execution",
    "description" : "Multi-Execution: Multicore Caching for Data-Similar Executions
这篇paper针对以multi-execution这种模式运行的程序提出了一种新的cache手段。
所谓multi-execution，指的是同时运行同一个程序的多个进程，而它们的输入数据又互不相同。这种模式在machine-learning领域比较常见，一些相对独立的learner可以以并行的方式被训练，而它们的结果可以通过一种叫做boosting的方式合并起来。给我的感觉似乎有点像mapreduce？
然后呢，作者们发现以这种方式运行的程序进程的数据有很大一部分是相同的，在合并cache数据上可以做一下文章，节省cache的使用。
于是这篇paper提出了一种叫做mergeable cache的架构，用于代替传统的L2 cache，L1 cache还是传统的cache架构。首先假设相同的数据的虚拟地址往往也是相同的（应该去掉了address space randomization的影响），以类似Page Coloring的策略进行物理页的分配，使得不同进程同一虚拟地址所对应的物理页都是相邻的。然后把虚拟地址的头9位作为cache tag，再为每个cache line记录一个bit vector用以表示某个processor的数据是否保存在这条cache line中。于是L2 cache hit当且仅当： 1. 虚拟地址的头9位等于cache line的tag 2. cache line中的bit vector的processor对应的位被置上
另外为了简化cache策略，L1和L2的数据内容是互斥的，或者说一段被cache的数据要么在L1，要么在L2，不可能同时存在于两者中。这样一来L2就只有从L1淘汰出来的数据了，而L2中的数据修改分三步完成： 1. 把数据从L2中标记为不存在（对应processor的bit vector位置0） 2. 数据进入L1 3. 修改数据
这就是这篇paper提出的cache架构的主要内容，后面的evaluation部分做的也很不错。从数据中可以看出合并的cache里面dirty cache占了比较大的比例，从而说明简单的copy-on-write策略的效果不会很好，因为copy-on-write只能合并clean cache。最后平均的speedup提升在2.5x左右，很不错。但是对于数据无关的并行程序运行，会产生一定的overhead，此时可以选择传统的L2 cache机制。",
    "inLanguage" : "en-US",
    "author" : "zellux",
    "creator" : "zellux",
    "publisher": "zellux",
    "accountablePerson" : "",
    "copyrightHolder" : "",
    "copyrightYear" : "2009",
    "datePublished": "2009-05-12 00:00:00 &#43;0000 UTC",
    "dateModified" : "2009-05-12 00:00:00 &#43;0000 UTC",
    "url" : "https://blog.yxwang.me/2009/05/isca-09-multi-execution/",
    "wordCount" : "41",
    "keywords" : [ "Cache","Computer System","ISCA","Memory Management","Paper","Blog" ]
}
</script>

  </head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <span class="site-title">
      <a href="https://blog.yxwang.me/">Aiur · Zellux 的博客</a>
    </span>
    
    <div class="nav-list">
      
      <span class="nav-item"><a href="/about">About</a></span>
      
      <span class="nav-item"><a href="/archive">Archive</a></span>
      
      <span class="nav-item"><a href="/notes">Notes</a></span>
      
    </div>
  </div>
</nav>

    <div class="container">


<div class="content">
  <div class="post">
    <h1 class="post-title"><a href="https://blog.yxwang.me/2009/05/isca-09-multi-execution/">ISCA 09 - Multi-Execution</a></h1>
    <span class="post-meta">
  <time datetime='Tue, May 12, 2009' data-updated="true" itemprop="datePublished">Tue, May 12, 2009</time>
  
  <span class="post-categories">
    •
	<a href="https://blog.yxwang.me/categories/computer-system">Computer System</a>
  </span>
  
</span>

    <div class="post-content">
      <p>Multi-Execution: Multicore Caching for Data-Similar Executions</p>

<p>这篇paper针对以multi-execution这种模式运行的程序提出了一种新的cache手段。</p>

<p>所谓multi-execution，指的是同时运行同一个程序的多个进程，而它们的输入数据又互不相同。这种模式在machine-learning领域比较常见，一些相对独立的learner可以以并行的方式被训练，而它们的结果可以通过一种叫做boosting的方式合并起来。给我的感觉似乎有点像mapreduce？</p>

<p>然后呢，作者们发现以这种方式运行的程序进程的数据有很大一部分是相同的，在合并cache数据上可以做一下文章，节省cache的使用。</p>

<p>于是这篇paper提出了一种叫做mergeable cache的架构，用于代替传统的L2 cache，L1 cache还是传统的cache架构。首先<strong>假设相同的数据的虚拟地址往往也是相同的</strong>（应该去掉了address space randomization的影响），以类似<a href="http://techblog.iamzellux.com/2009/05/page-coloring/" target="_blank">Page Coloring</a>的策略进行物理页的分配，使得不同进程同一虚拟地址所对应的物理页都是相邻的。然后把虚拟地址的头9位作为cache tag，再为每个cache line记录一个bit vector用以表示某个processor的数据是否保存在这条cache line中。于是L2 cache hit当且仅当：
1. 虚拟地址的头9位等于cache line的tag
2. cache line中的bit vector的processor对应的位被置上</p>

<p>另外为了简化cache策略，<strong>L1和L2的数据内容是互斥的</strong>，或者说一段被cache的数据要么在L1，要么在L2，不可能同时存在于两者中。这样一来L2就只有从L1淘汰出来的数据了，而L2中的数据修改分三步完成：
1. 把数据从L2中标记为不存在（对应processor的bit vector位置0）
2. 数据进入L1
3. 修改数据</p>

<p>这就是这篇paper提出的cache架构的主要内容，后面的evaluation部分做的也很不错。从数据中可以看出合并的cache里面dirty cache占了比较大的比例，从而说明简单的copy-on-write策略的效果不会很好，因为copy-on-write只能合并clean cache。最后平均的speedup提升在2.5x左右，很不错。但是对于数据无关的并行程序运行，会产生一定的overhead，此时可以选择传统的L2 cache机制。</p>

    </div>
        <div class="cc-license">
      本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.zh">知识共享署名-非商业性使用 3.0 版本许可协议</a>进行许可，欢迎转载，演绎，但是必须保留本文的署名 <a href="https://blog.yxwang.me/2009/05/isca-09-multi-execution/">zellux</a>（包含链接），且不得用于商业目的。
    </div>

  </div>
  <div class="pagination">
    <a class="btn previous " href="https://blog.yxwang.me/2009/05/install-git-gitoss-gitweb-in-archlinux/"> Prev</a>  
    <a class="btn next " href="https://blog.yxwang.me/2009/05/page-coloring/"> Next</a> 
  </div>
</div>


<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
  this.page.url = "https://blog.yxwang.me/2009/05/isca-09-multi-execution/";
  
  };
  (function() {
  var d = document, s = d.createElement('script');
  s.src = '//aiur-zellux.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



<div class="footer">
  
  <p>Powered by <a href="http://gohugo.io">Hugo</a> and <a href="https://github.com/zhe/hugo-theme-slim">Slim theme</a>.
  
      Follow me on <a href="https://twitter.com/zellux">Twitter</a>.
      </p>
  </p>
  
</div>

                   
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      argmax: "\\operatorname*{argmax}",
      argmin: "\\operatorname*{argmin}"
    }
  },
  jax: ["input/TeX","output/CommonHTML"]
});
</script>

<script type="text/javascript" async
  src="/MathJax/MathJax.js?config=TeX-AMS_CHTML">
</script>

</script>

<script src="https://blog.yxwang.me/js/slim.min.aef36e671f72c9042139aae327dbe693b7ebaa67fd56f30dad4c985a91ba9294.js"></script>


<link rel="stylesheet" href="https://blog.yxwang.me/css/solarized-light.min.5499f6bc45da0c78f070be4f720fd28b19af75306b569b77837d57c3cf819430.css" />
<script src="/js/highlight.pack.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>

</div>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-25551121-1', 'auto');
ga('send', 'pageview');

</script>

<script type="text/javascript">
    window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
      heap.load("3166778701");
</script>


</body>

</html>

