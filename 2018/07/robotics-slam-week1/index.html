<!DOCTYPE html>
<html lang="zh-CN">

  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="description" content="最近宾大在 Coursera 上开了一个机器人系列课程，包含了视觉、运动规划、机械设计等课题。我对 SLAM 很感兴趣，于是就选了 Robotics Estimation and Learning 这门课。第一周的内容是高斯分布。">
    <meta name="author" content="zellux">

    <title> SLAM 笔记 1：高斯分布 &middot; Aiur · Zellux 的博客 </title>

    <script src="/js/jquery-3.2.1.min.js"></script>
    <link rel="stylesheet" href="/css/jquery.fancybox.min.css" />
    <script src="/js/jquery-3.0.47.fancybox.min.js"></script>

    
    
    <link rel="stylesheet" href="https://blog.yxwang.me/css/slim.min.9d45622fec7b2cd2951a999932cee68b646d2042591570a54846f1b9c85b69aa.css">
    
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Source+Code+Pro' rel='stylesheet' type='text/css'>
    
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.ico">

    
    <link href="" rel="alternate" type="application/rss+xml" title="Aiur · Zellux 的博客" />
    
<script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://blog.yxwang.me/"
    },
    "articleSection" : "post",
    "name" : "SLAM 笔记 1：高斯分布",
    "headline" : "SLAM 笔记 1：高斯分布",
    "description" : "<p>最近宾大在 Coursera 上开了一个<a href="https://www.coursera.org/specializations/robotics">机器人系列课程</a>，包含了视觉、运动规划、机械设计等课题。我对 <a href="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping">SLAM</a> 很感兴趣，于是就选了 Robotics Estimation and Learning 这门课，课程主页是<a href="https://www.coursera.org/learn/robotics-learning/" class="uri">https://www.coursera.org/learn/robotics-learning/</a>。第一周的内容是高斯分布。</p>",
    "inLanguage" : "en-US",
    "author" : "zellux",
    "creator" : "zellux",
    "publisher": "zellux",
    "accountablePerson" : "",
    "copyrightHolder" : "",
    "copyrightYear" : "2018",
    "datePublished": "2018-07-23 00:18:32 &#43;0000 UTC",
    "dateModified" : "2018-07-23 00:18:32 &#43;0000 UTC",
    "url" : "https://blog.yxwang.me/2018/07/robotics-slam-week1/",
    "wordCount" : "353",
    "keywords" : [ "Courses","Robotics","Notes","Blog" ]
}
</script>

  </head>

  <body>
    <nav class="nav">
  <div class="nav-container">
    <span class="site-title">
      <a href="https://blog.yxwang.me/">Aiur · Zellux 的博客</a>
    </span>
    
    <div class="nav-list">
      
      <span class="nav-item"><a href="/about">About</a></span>
      
      <span class="nav-item"><a href="/archive">Archive</a></span>
      
      <span class="nav-item"><a href="/notes">Notes</a></span>
      
    </div>
  </div>
</nav>

    <div class="container">


<div class="content">
  <div class="post">
    <h1 class="post-title"><a href="https://blog.yxwang.me/2018/07/robotics-slam-week1/">SLAM 笔记 1：高斯分布</a></h1>
    <span class="post-meta">
  <time datetime='Mon, Jul 23, 2018' data-updated="true" itemprop="datePublished">Mon, Jul 23, 2018</time>
  
  <span class="post-categories">
    •
	<a href="https://blog.yxwang.me/categories/robotics">Robotics</a>
  </span>
  
</span>

    <div class="post-content">
      <p>最近宾大在 Coursera 上开了一个<a href="https://www.coursera.org/specializations/robotics">机器人系列课程</a>，包含了视觉、运动规划、机械设计等课题。我对 <a href="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping">SLAM</a> 很感兴趣，于是就选了 Robotics Estimation and Learning 这门课，课程主页是<a href="https://www.coursera.org/learn/robotics-learning/" class="uri">https://www.coursera.org/learn/robotics-learning/</a>。第一周的内容是高斯分布。</p>
<h2 id="一元高斯分布">一元高斯分布</h2>
<p>给定数据集 <span class="math inline">\(\{x_i\}\)</span>，可以通过最大似然 (Maximum Likelihood Estimate) 来估计均值 <span class="math inline">\(\mu\)</span> 和标准差 <span class="math inline">\(\sigma\)</span> <span class="math display">\[
\hat{\mu}, \hat{\sigma}=\argmax_{\mu, \sigma}{p(\{x_i\}|\mu, \sigma)}
\]</span></p>
<p>假设所有观测数据独立分布，则有</p>
<p><span class="math display">\[
p(\{x_i\}|\mu, \sigma) = \prod_{i=1}^N p(x_i|\mu, \sigma)
\]</span></p>
<p>解这个优化函数：</p>
<p><span class="math display">\[
\begin{align}
\hat{\mu}, \hat{\sigma} 
&amp;= \argmax_{\mu, \sigma} \prod_{i=1}^N p(x_i|\mu, \sigma) \\
&amp;= \argmax_{\mu, \sigma} \prod_{i=1}^N \ln p(x_i|\mu, \sigma) \\
&amp;= \argmax_{\mu, \sigma} \prod_{i=1}^N \ln (\frac{1}{\sqrt{2\pi}\sigma} \exp(-\frac{(x_i-\mu)^2}{2\sigma^2}))
\end{align}
\]</span></p>
<p>设损失函数 <span class="math inline">\(J(\mu, \sigma) =\sum_{i=1}^N (\frac{(x_i-\mu)^2}{2\sigma^2} + \ln{\sigma})\)</span>，则有 <span class="math inline">\(\hat{\mu}, \hat{\sigma} = \argmin_{\mu, \sigma} J(\mu, \sigma)\)</span></p>
<p><span class="math display">\[
\begin{align}
\frac{\partial{J}}{\partial{\mu}}
&amp;=\frac{\partial{}}{\partial{\mu}}\sum_{i=1}^N (\frac{(x_i-\mu)^2}{2\sigma^2} + \ln{\sigma})
=\sum_{i=1}^N (\frac{\partial{}}{\partial{\mu}}\frac{(x_i-\mu)^2}{2\sigma^2}) \\
\frac{\partial{J}}{\partial{\sigma}}
&amp;=\frac{\partial{}}{\partial{\sigma}}\sum_{i=1}^N (\frac{(x_i-\mu)^2}{2\sigma^2} + \ln{\sigma})
=(\frac{\partial}{\partial{\sigma}} \frac{1}{2\sigma^2}) (\sum_{i=1}^N (x_i-\mu)^2) + \frac{N}{\sigma})
\end{align}
\]</span></p>
<p>求极值令两式都为 0，可以解得 <span class="math display">\[
\begin{align}
\hat{\mu} &amp;= \frac{1}{N} \sum_{i=1}^{N} x_i \\
\hat{\sigma}^2 &amp;= \frac{1}{N} \sum_{i=1}^N (x_i - \hat{\mu})^2
\end{align}
\]</span></p>
<h2 id="多元高斯分布">多元高斯分布</h2>
<p><span class="math display">\[
p(x) = \frac{1}{(2\pi)^{\frac{D}{2}} |\Sigma|^{\frac{1}{2}}} \exp(-\frac{1}{2}(\pmb{x} - \pmb{\mu})^T \Sigma^{-1} (\pmb{x} - \pmb{\mu}))
\]</span></p>
<ul>
<li><span class="math inline">\(D\)</span>: 维数</li>
<li><span class="math inline">\(\pmb{X}\)</span>: 数据集</li>
<li><span class="math inline">\(\pmb{\mu}\)</span>: 均值向量</li>
<li><span class="math inline">\(\Sigma\)</span>: 协方差矩阵 (covariance matrix)，对角线元素表示方差，非对角线元素表示变量相关性</li>
</ul>
<p>用最大似然估计多元高斯分布：</p>
<p><span class="math display">\[
\hat{\pmb{\mu}}, \hat{\Sigma}=\argmax_{\pmb{\mu}, \Sigma}{p(\{\pmb{x}_i\}|\pmb{\mu}, \Sigma)}
\]</span> 类似于一元高斯分布，假设所有观测独立，则有 <span class="math display">\[
\begin{align}
\hat{\pmb{\mu}}, \hat{\Sigma} &amp;= \argmax_{\pmb{\mu}, \Sigma} \prod{p(\pmb{x}_i|\pmb{\mu}, \Sigma)} \\
&amp;= \argmax_{\pmb{\mu}, \sigma} \prod_{i=1}^N \ln p(x_i|\pmb{\mu}, \sigma) \\
&amp;= \argmax_{\pmb{\mu}, \sigma} \sum_{i=1}^N (-\frac{1}{2}(\pmb{x}_i - \pmb{\mu})^T \Sigma^{-1} (\pmb{x}_i - \pmb{\mu}) - \frac{1}{2}\ln |\Sigma| + C) \\
&amp;= \argmin_{\pmb{\mu}, \sigma} \sum_{i=1}^N (\frac{1}{2}(\pmb{x}_i - \pmb{\mu})^T \Sigma^{-1} (\pmb{x}_i + \pmb{\mu}) + \frac{1}{2}\ln |\Sigma|)
\end{align}
\]</span></p>
<p>设损失函数 <span class="math inline">\(J(\pmb{\mu, \Sigma}) = \sum_{i=1}^N (\frac{1}{2}(\pmb{x}_i - \pmb{\mu})^T \Sigma^{-1} (\pmb{x}_i + \pmb{\mu}) + \frac{1}{2}\ln |\Sigma|))\)</span>，用类似估计一元高斯分布的方法，令 <span class="math inline">\(\frac{\partial{J}}{\partial{\pmb{\mu}}}\)</span> 和 <span class="math inline">\(\frac{\partial{J}}{\partial{\Sigma}}\)</span> 为 0，可以解得 <span class="math display">\[
\begin{align}
\hat{\pmb{\mu}} &amp;= \frac{1}{N} \sum_{i=1}^{N} \pmb{x}_i \\
\hat{\Sigma} &amp;= \frac{1}{N} \sum_{i=1}^N (\pmb{x}_i - \hat{\pmb{\mu}})(\pmb{x}_i - \hat{\pmb{\mu}})^T
\end{align}
\]</span></p>
<h2 id="高斯混合模型-gaussian-mixture-model">高斯混合模型 (Gaussian Mixture Model)</h2>
<p>GMM 就是多个高斯模型的加权和：</p>
<p><span class="math display">\[
p(x) = \sum_{k=1}^K w_k g_k (\pmb{x}|\pmb{u}_k, \Sigma_k)
\]</span></p>
<ul>
<li><span class="math inline">\(g_k\)</span>: 单个高斯分布函数</li>
<li><span class="math inline">\(w_k\)</span>: 权值函数，总和为 1</li>
</ul>
<p>解 GMM 的方法之一就是 EM (Expectation-Maximization)。</p>
<h3 id="em-法解-gmm">EM 法解 GMM</h3>
<p>引入隐含变量 <span class="math display">\[
z_k^i = \frac{g_k(\pmb{x}_i) | \pmb{u}_k, \Sigma_k}{\sum_{k=1}^K g_k(\pmb{x}_i) | \pmb{u}_k, \Sigma_k}
\]</span></p>
<p><span class="math inline">\(z_k^i\)</span> 的表示第 i 个观测数据中，第 k 个高斯函数占全体的比重，直观表示如下图</p>
<figure>
<img src="/images/2018-07/gmm-em-z-graph.png" alt="z_k^i 的直观表示" /><figcaption><span class="math inline">\(z_k^i\)</span> 的直观表示</figcaption>
</figure>
<p>均值向量和协方差矩阵可以通过 <span class="math inline">\(z_k\)</span> 估计 <span class="math display">\[
\begin{align}
\hat{\pmb{\mu}}_k &amp;= \frac{1}{z_k} \sum_{i=1}{N} z_k^i \pmb{x}_i \\
\hat{\Sigma}_k &amp;= \frac{1}{z_k} \sum_{i=1}{N} z_k^i (\pmb{x}_i - \hat{\pmb{\mu_k}})(\pmb{x}_i - \hat{\pmb{\mu_k}})^T \\
z_k &amp;= \sum_{i=1}^N z_k^i
\end{align}
\]</span></p>
<h3 id="em-法具体过程">EM 法具体过程</h3>
<ol type="1">
<li>初始化 <span class="math inline">\(\pmb{\mu}\)</span> and <span class="math inline">\(\Sigma\)</span></li>
<li>固定 <span class="math inline">\(\pmb{\mu}\)</span> 和 <span class="math inline">\(\Sigma\)</span>，并更新 <span class="math inline">\(z_k^i\)</span> 的值 (E-step)</li>
<li>固定 <span class="math inline">\(z_k^i\)</span>，并更新 <span class="math inline">\(\pmb{\mu}\)</span> 和 <span class="math inline">\(\Sigma\)</span> 的值 (M-step)</li>
<li>重复第 2、3 步，直到稳定</li>
</ol>
<h2 id="全课程的笔记链接">全课程的笔记链接</h2>
<ul>
<li>Robotics Estimation and Learning 的<a href="https://www.coursera.org/learn/robotics-learning/">课程主页</a></li>
<li>第一周笔记：高斯分布</li>
<li><a href="/2018/07/robotics-slam-week2/">第二周笔记：卡尔曼滤波</a></li>
<li><a href="/2018/08/robotics-slam-week3/">第三周笔记：地图</a></li>
<li><a href="/2018/08/robotics-slam-week4/">第四周笔记：定位</a></li>
</ul>
    </div>
        <div class="cc-license">
      本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.zh">知识共享署名-非商业性使用 3.0 版本许可协议</a>进行许可，欢迎转载，演绎，但是必须保留本文的署名 <a href="https://blog.yxwang.me/2018/07/robotics-slam-week1/">zellux</a>（包含链接），且不得用于商业目的。
    </div>

  </div>
  <div class="pagination">
    <a class="btn previous " href="https://blog.yxwang.me/2018/07/robotics-slam-week2/"> Prev</a>  
    <a class="btn next " href="https://blog.yxwang.me/2018/07/sous-vide-lobster/"> Next</a> 
  </div>
</div>


<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
  this.page.url = "https://blog.yxwang.me/2018/07/robotics-slam-week1/";
  
  };
  (function() {
  var d = document, s = d.createElement('script');
  s.src = '//aiur-zellux.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



<div class="footer">
  
  <p>Powered by <a href="http://gohugo.io">Hugo</a> and <a href="https://github.com/zhe/hugo-theme-slim">Slim theme</a>.
  
      Follow me on <a href="https://twitter.com/zellux">Twitter</a>.
      </p>
  </p>
  
</div>

                   
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      argmax: "\\operatorname*{argmax}",
      argmin: "\\operatorname*{argmin}"
    }
  },
  jax: ["input/TeX","output/CommonHTML"]
});
</script>

<script type="text/javascript" async
  src="/MathJax-2.7.5/MathJax.js?config=TeX-AMS_CHTML">
</script>

</script>

<script src="https://blog.yxwang.me/js/slim.min.aef36e671f72c9042139aae327dbe693b7ebaa67fd56f30dad4c985a91ba9294.js"></script>


<link rel="stylesheet" href="https://blog.yxwang.me/css/solarized-light.min.5499f6bc45da0c78f070be4f720fd28b19af75306b569b77837d57c3cf819430.css" />
<script src="/js/highlight.pack.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>

</div>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-25551121-1', 'auto');
ga('send', 'pageview');

</script>

<script type="text/javascript">
    window.heap=window.heap||[],heap.load=function(e,t){window.heap.appid=e,window.heap.config=t=t||{};var r=t.forceSSL||"https:"===document.location.protocol,a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=(r?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+e+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(e){return function(){heap.push([e].concat(Array.prototype.slice.call(arguments,0)))}},p=["addEventProperties","addUserProperties","clearEventProperties","identify","removeEventProperty","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
      heap.load("3166778701");
</script>


</body>

</html>

